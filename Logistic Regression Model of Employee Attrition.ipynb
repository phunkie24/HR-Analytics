{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea86f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa36631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HR Analytics\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# File location and type\n",
    "file_location = r\"C:\\Users\\HP\\Downloads\\Big Data Analytics\\Data Science Projects\\Data Science Internship\\Project 3 - HR Analytics-20231111T083906Z-001\\Project 3 - HR Analytics\\Data P3 MeriSKILL\\HR-Employee-Attrition.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "df = spark.read.format(file_type) \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(file_location)\n",
    "\n",
    "# Select the relevant columns\n",
    "columns = ['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n",
    "           'Education', 'EducationField', 'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction',\n",
    "           'Gender', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
    "           'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18', 'OverTime',\n",
    "           'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours',\n",
    "           'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "           'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "\n",
    "df = df.select(columns)\n",
    "\n",
    "# Convert the Spark DataFrame to a Pandas DataFrame\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae60065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for column in ['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']:\n",
    "    pdf[column] = le.fit_transform(pdf[column])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = pdf.drop(['Attrition'], axis=1)\n",
    "y = pdf['Attrition']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=115000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f9e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics:\n",
      "      Metric     Value\n",
      "0   Accuracy  0.866213\n",
      "1  Precision  0.839805\n",
      "2     Recall  0.866213\n",
      "3   F1 Score  0.844194\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score     support\n",
      "0              0.888620  0.965789  0.925599  380.000000\n",
      "1              0.535714  0.245902  0.337079   61.000000\n",
      "accuracy       0.866213  0.866213  0.866213    0.866213\n",
      "macro avg      0.712167  0.605846  0.631339  441.000000\n",
      "weighted avg   0.839805  0.866213  0.844194  441.000000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[367  13]\n",
      " [ 46  15]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# Convert classification report to DataFrame\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Create a DataFrame to store overall metrics\n",
    "overall_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Overall Metrics:\")\n",
    "print(overall_metrics)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_df)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429684b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
